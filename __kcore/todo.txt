//List of TODO:s.

// VSwamp:
* Implement backward linking of swamp info nodes. Right now when you free to
  the swamp, the kernel will only join adjacent nodes forward. If there are
  adjacent nodes behind you, it will not join them up, and thus will cause
  fragmentation.

Portions of the C++11 Stdlib that we will port to the kernel:
	* <atomic>
	* <memory>
	* <functional>
	* <new>
	* <iterator>
	* <bitset>
	* <__kcallbacks>

Messages: Done
	Unify all request and response messages, such that we potentially no
	longer have to delete the request message and create a new response
	message every time (for kernel-domain servers at least).

	This basically means that we no longer copy the messages when pulling
	in MessageStream::pull(), but we hand out pointers as they are.

	This is safe because: if the address spaces are different, it will
	only matter if the processes are userspace. Kernel-domain source
	threads can (and should) directly allocate their buffers.
	Kernel-domain target threads can (and should) directly use the kernel
	buffer.

	Should kernel domain targets be made to use the userspace syscall
	entry stubs? No. Even for the case where we intended (and we don't
	anymore, mind you) to have kernel-domain services, we were going to
	have them use jump-buffers to directly access kernel data and code
	for modifying stream metadata. So we would have just exposed the
	direct kernel entry points to them via the jump buffers, and not the
	syscall stubs.

	The only downside to not copying the messages to the target is that
	the target can directly modify the message that the source sent.

	To a degree, we will still need to do some small copying, since for
	most servers, they will need to create a copy of the request message
	on their stack before they reuse it as the response.

Rename classes: Done.
	Classes will no longer have names of the form classC, but rather,
	we will follow the Java convention of calling classes Class with an
	upper camel case name.

__kcallbacks: Designed and implemented. Integrating.
	We need a way to allow threads to spin on one queue, while specifying
	their callbacks in a clean, easily readable way.

	baseclass: __kCallback:
		class __kCallback
		{
			__kCallback(void(*)(void));
			__kCallback(void(*)(...));
		};

Eliminating per-cpu threads: Halfway done.
	We should give each CPU its own power thread of sorts. This is the
	thread it executes in while waking up, and which it uses for
	power events. This thread also leads it to the scheduler's pull()
	method.

	By doing this, we eliminate the need for per-CPU threads, and can
	unify a lot of code. It also leaves CPUs addressable. This means
	that while CPUs are waking up, their threads will have unique IDs,
	so the problem we had 2 or so years back with multiple CPUs being
	able to acquire a lot simultaneously (because they all had the same
	TID to the lock) cannot occur.

	#2: Solution #2 is to add special case handling code to the locking
	code in the kernel, such that we check the IDs of threads on
	acquire. If the ID of the thread is within the CPU namespace, we
	store the ID of the CPU instead of the ID of the thread. Very simple,
	and it eliminates the idea of per-cpu threads entirely.

	A problem arises, where if the threadId is not unique, AP CPUs running
	the same power thread will be unaddressable. This means they will be
	unable to receive messages from kernel services. We can solve this
	using a getThreadId() method on Thread. It will return the current
	CPU ID if the thread is a power thread, or else its own hardcoded ID.

	Problem with this approach is that CPUs are not messageable. So we cannot
	make async syscalls and get the responses back using this approach,
	unless we split some amount of the per-cpu context among CPUs.

	This is essentially what we've done now. There is no good way to
	implement this approach. The memory saving isn't worth the nastiness.
	Making it polymorphic is too hard and requires too many functions.

	Approach #1 is the only reasonable method we can employ.

	The good thing about approach #1 is that it may inherently also solve
	the current untidy situation where we have to start a new thread in the
	middle of __korientation because we can't safely use the kernel's
	boot thread with confidence due to loose ends in its state.

	If we use a solid single-type Thread based approach, with a separate
	thread on each CPU, we'll probably end up with greater benefits in the
	long run.

	Since this is the next thing we'll be fixing, I'd recommend you give it
	some deep thought.

Kernel startup sequence:
	I want to transform the kernel into essentially a micro-biased-hybrid
	kernel. Maybe, a hybrid microkernel. Something along those lines. I'm
	sincerely considering making a deep-seated messaging infrastructure, and
	making everything message passed.

	In such a design, one would have to change the way the kernel puts out
	its dependencies. For a hybrid kernel, you should aim to satisfy dependencies
	in this order:

		Base kernel environment.
		Language environment.
		Memory Management (which should not use message passing.)
		Scheduling.
		Processes.
		Threads.
		Message queues.
		<Everything else>

	We will be aiming to force the kernel to follow this format over the
	next few patches.

	Essentially, this will mean that we will have to force
	certain subsystems to refrain from using demand paging? Or, maybe not.
	The MM will never page fault, and everything else is initialized after
	it.

	I'm sure we'll find a workaround anywaty.

BSP Plug status:
	* Make it a global status variable and not a per-cpu state.

Kernel-server thread IPC/ITC mechanism:

Isolate the ipc:: namespace code into its own .cpp file:

Establishing specific "ID" nomenclature:
	We should no longer have any classes with members named "id". All
	"id" members should be given more specific names (cpuId, threadId,
	processId, etc).

fplainn:: namespace:
	* Concurrency protect Device.
	* Concurrency protect Driver.
	* Concurrency protect DeviceInstance.
	* Concurrency protect DriverInstance.

